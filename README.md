# LLM Engineering
This project has use cases I used to learn more about LLM engineering.

Local models are on a VirtualBox VM with 16GB RAM and 8 CPUs.

## website_summarizer
- Use OpenAI API to summarize web page content and return the summary in Markdown.
- Do the same with a local version of llama3.2.
- Responses are saved by model name.

Local models spiked VM CPU 100% causing desktop fans to come on. Lots of resources for a seemingly simple task.