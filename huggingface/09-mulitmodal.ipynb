{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyON0/reBKeauJ9eZubl4uFK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## Multimodal"],"metadata":{"id":"9EYckQTYl_Lx"}},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"967WyIqKl7OA"},"outputs":[],"source":["!pip install transformers torch bitsandbytes accelerate datasets peft"]},{"cell_type":"code","source":["def show_model_size(model):\n","    config = model.config\n","    q=0\n","\n","    if hasattr(config, \"quantization_config\") and config.quantization_config is not None:\n","        q_config = config.quantization_config\n","\n","        if hasattr(q_config, \"load_in_4bit\") and q_config.load_in_4bit == True:\n","            q = 4\n","        elif hasattr(q_config, \"load_in_8bit\") and q_config.load_in_8bit == True:\n","            q = 8\n","    else:\n","        if hasattr(config, \"torch_dtype\") and config.torch_dtype is not None:\n","            q = config.torch_dtype.itemsize * 8\n","\n","    gbs = model.get_memory_footprint() / 1e9\n","    print(f\"----- {q}-bit Model -----\")\n","    print(f\"Number of parameters: {model.num_parameters():,}\")\n","    print(f\"Memory footprint if FP32: {model.num_parameters()*4/1e9:.2f} GB\")\n","    print(f\"Memory footprint: {gbs:.2f} GB\")\n","    print(f\"Model device: {next(model.parameters()).device}\")"],"metadata":{"id":"leUJH_lUteWK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Load model as 4-bit"],"metadata":{"id":"QJyFJih-uj_D"}},{"cell_type":"code","source":["from transformers import AutoProcessor, AutoModelForPreTraining, BitsAndBytesConfig\n","import torch\n","\n","MODEL = \"llava-hf/llava-1.5-7b-hf\"\n","\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.bfloat16\n",")\n","\n","processor = AutoProcessor.from_pretrained(MODEL)\n","\n","model = AutoModelForPreTraining.from_pretrained(\n","    MODEL,\n","    device_map=\"auto\",\n","    quantization_config=bnb_config,\n","    torch_dtype=torch.bfloat16\n",")"],"metadata":{"collapsed":true,"id":"eYDCYNZimIX5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["show_model_size(model)"],"metadata":{"id":"G0OuSal3tiJk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Load images"],"metadata":{"id":"dpfIEG4lummH"}},{"cell_type":"code","source":["from transformers.image_utils import load_image\n","\n","image1 = load_image(\"/content/content/bird+walking+on+grass.jpeg\")\n","image2 = load_image(\"/content/content/cat+sitting+on+table.jpeg\")"],"metadata":{"id":"bbQvvyaMuoMQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image1"],"metadata":{"id":"h9cPGNIY2-Mq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image2"],"metadata":{"id":"xKs8Jq-m2_ju"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Generate Captions"],"metadata":{"id":"d4RtdDkY3BYi"}},{"cell_type":"code","source":["messages = [\n","    {\n","        \"role\": \"user\",\n","        \"content\": [\n","            {\"type\": \"image\"},\n","            {\"type\": \"text\", \"text\": \"Describe this image.\"},\n","        ]\n","    },\n","    {\n","        \"role\": \"assistant\",\n","        \"content\": [\n","            {\"type\": \"text\", \"text\": \"A small brown bird standing on top of a lush green field of grass.\"},\n","        ]\n","    },\n","    {\n","        \"role\": \"user\",\n","        \"content\": [\n","            {\"type\": \"image\"},\n","            {\"type\": \"text\", \"text\": \"Describe this image.\"},\n","        ]\n","    }\n","]\n","\n","prompt = processor.apply_chat_template(messages, add_generation_prompt=True)\n","inputs = processor(text=prompt, images=[image1, image2], return_tensors=\"pt\")\n","\n","model_device = next(model.parameters()).device\n","inputs = {k: v.to(model_device) for k, v in inputs.items()}"],"metadata":{"id":"-Zf4PmQW3A4K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(prompt)"],"metadata":{"id":"b6bMTUyF4p9a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["generate_ids = model.generate(**inputs, max_new_tokens=100, eos_token_id=processor.tokenizer.eos_token_id, do_sample=True, temperature=0.7)\n","generated_texts = processor.batch_decode(generate_ids, skip_special_tokens=True)\n","print(generated_texts)"],"metadata":{"id":"zt2KgO_t5TVN"},"execution_count":null,"outputs":[]}]}