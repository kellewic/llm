{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","authorship_tag":"ABX9TyN+X1NwJpa+m3Dg7WIFNiJA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## Fine Tuning\n","Had to switch from my lab VM to Google Collab for this since I needed a GPU."],"metadata":{"id":"pfzdmQyac8bQ"}},{"cell_type":"code","source":["!pip install transformers datasets evaluate transformers[torch] py7zr"],"metadata":{"collapsed":true,"id":"G_kbSuMddBxN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Full fine-tuning for summarization"],"metadata":{"id":"Duvn4E52d6_l"}},{"cell_type":"code","source":["## Load model and tokenizer\n","from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n","MODEL = \"facebook/bart-large-cnn\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(MODEL)\n","model = AutoModelForSeq2SeqLM.from_pretrained(MODEL)"],"metadata":{"collapsed":true,"id":"bm9o-4CDeKFZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Load dataset"],"metadata":{"id":"xyxAGhm8ey74"}},{"cell_type":"code","source":["from datasets import load_dataset\n","dataset = load_dataset(\"knkarthick/samsum\")\n","\n","## Clean dataset\n","dataset = dataset.remove_columns(['id'])\n","dataset = dataset.filter(lambda example: example['dialogue'] is not None)\n","\n","## Shrink dataset for training\n","PERCENT = 1\n","\n","dataset['train'] = dataset['train'].shuffle(seed=42).select(range(int(len(dataset['train'])*PERCENT)))\n","dataset['test'] = dataset['test'].shuffle(seed=37).select(range(int(len(dataset['test'])*PERCENT)))\n","dataset['validation'] = dataset['validation'].shuffle(seed=4).select(range(int(len(dataset['validation'])*PERCENT)))\n","\n","dataset"],"metadata":{"collapsed":true,"id":"hsE0vNbNfP8x"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Test summarization of base model"],"metadata":{"id":"UgPFuGr7hEZh"}},{"cell_type":"code","source":["sample = dataset[\"test\"][0]['dialogue']\n","label = dataset[\"test\"][0]['summary']\n","\n","def generate_summary(input, llm):\n","  prompt = f\"\"\"\n","  Summarize the following conversation.\n","\n","  {input}\n","\n","  Summary:\n","  \"\"\"\n","\n","  input_ids = tokenizer(prompt, return_tensors=\"pt\")\n","  output = llm.generate(input_ids[\"input_ids\"], max_new_tokens=200)\n","  return tokenizer.decode(output[0], skip_special_tokens=True)\n","\n","output = generate_summary(sample, model)\n","print(\"Sample\")\n","print(sample)\n","print(\"----------------------------------------\")\n","print(\"Model Generated Summary\")\n","print(output)\n","print(\"Correct Summary\")\n","print(label)"],"metadata":{"collapsed":true,"id":"wjwMAyk3fsTd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Prepare the dataset"],"metadata":{"id":"71AYdMl4hRp1"}},{"cell_type":"code","source":["def tokenize_inputs(example):\n","    start_prompt = 'Summarize the following conversation.\\n\\n'\n","    end_prompt = '\\n\\nSummary: '\n","\n","    # Tokenize inputs\n","    prompt = [start_prompt + dialogue + end_prompt for dialogue in example[\"dialogue\"]]\n","    model_inputs = tokenizer(prompt, padding=\"max_length\", max_length=200, truncation=True)\n","\n","    # Tokenize labels\n","    labels = tokenizer(example[\"summary\"], padding=\"max_length\", max_length=200, truncation=True)\n","\n","    labels[\"input_ids\"] = [\n","        [(label if label != tokenizer.pad_token_id else -100) for label in label_seq]\n","        for label_seq in labels[\"input_ids\"]\n","    ]\n","\n","    model_inputs[\"labels\"] = labels[\"input_ids\"]\n","    return model_inputs\n","\n","\n","tokenizer.pad_token = tokenizer.eos_token\n","tokenized_dataset = dataset.map(tokenize_inputs, batched=True)\n","tokenized_dataset = tokenized_dataset.remove_columns(['dialogue', 'summary'])\n","tokenized_dataset"],"metadata":{"collapsed":true,"id":"S3S2oLLvhVh8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Start training"],"metadata":{"id":"WK487169nJx8"}},{"cell_type":"code","source":["from huggingface_hub import notebook_login\n","notebook_login()"],"metadata":{"id":"iHSKwStanPSH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import TrainingArguments, Trainer\n","\n","MODEL = \"bart-cnn-samsum-finetuned\"\n","\n","training_args = TrainingArguments(\n","    output_dir=\"./\" + MODEL,\n","    hub_model_id=\"shayharding/\" + MODEL,\n","    learning_rate=1e-5,\n","    num_train_epochs=1,\n","    weight_decay=0.01,\n","    auto_find_batch_size=True,\n","    eval_strategy=\"epoch\",\n","    logging_steps=10\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    processing_class=tokenizer,\n","    args=training_args,\n","    train_dataset=tokenized_dataset[\"train\"],\n","    eval_dataset=tokenized_dataset[\"validation\"]\n",")"],"metadata":{"id":"9LrIP7AlnYGL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer.train()"],"metadata":{"collapsed":true,"id":"gBzXBIeloZHY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer.push_to_hub()"],"metadata":{"id":"WttjMrItqaRM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Test the fine-tuned model"],"metadata":{"id":"HTsPf_lWqwJT"}},{"cell_type":"code","source":["MODEL = \"shayharding/bart-cnn-samsum-finetuned\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(MODEL)\n","model = AutoModelForSeq2SeqLM.from_pretrained(MODEL)\n","\n","output = generate_summary(sample, model)\n","\n","print(\"Sample\")\n","print(sample)\n","print(\"----------------------------------------\")\n","print(\"Model Generated Summary\")\n","print(output)\n","print(\"Correct Summary\")\n","print(label)"],"metadata":{"id":"fOj-cG88qy0j"},"execution_count":null,"outputs":[]}]}