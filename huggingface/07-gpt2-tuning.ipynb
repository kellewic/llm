{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","authorship_tag":"ABX9TyOnb7xzjIq/tPzFItimVIDI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## GPT2 Model Tuning"],"metadata":{"id":"2OTTKWN5Ap3P"}},{"cell_type":"markdown","source":["### Get and pre-preocess dataset"],"metadata":{"id":"z3Q-H7XMDu03"}},{"cell_type":"code","source":["from datasets import load_dataset\n","\n","dataset = load_dataset(\"shayharding/reuters-articles\")\n","dataset"],"metadata":{"collapsed":true,"id":"9P9AXrMXAy2r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_full_article_col(example):\n","    return {'full_article': f\"TITLE:{example['title']}\\n\\nBODY:{example['body']}\" }\n","\n","dataset = dataset.map(create_full_article_col)\n","print(dataset)\n","print(dataset['train'][0]['full_article'])"],"metadata":{"collapsed":true,"id":"15gdYjHZBNbs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Get and create the model"],"metadata":{"id":"W76zOCLCD13j"}},{"cell_type":"code","source":["from transformers import AutoTokenizer\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"shayharding/gpt2-reuters-tokenizer\")"],"metadata":{"collapsed":true,"id":"S6Y9YON1B7Gk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["CONTEXT_LENGTH = 512\n","\n","def tokenize(element):\n","    return tokenizer(\n","        element[\"full_article\"],\n","        truncation=True,\n","        max_length=CONTEXT_LENGTH,\n","        return_overflowing_tokens=False\n","    )\n","\n","tokenized_dataset = dataset.map(tokenize, batched=True, remove_columns=dataset['train'].column_names)\n","tokenized_dataset"],"metadata":{"collapsed":true,"id":"o8QZLAHHCE27"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import GPT2LMHeadModel, AutoConfig, DataCollatorForLanguageModeling\n","\n","config = AutoConfig.from_pretrained(\n","    \"gpt2\",\n","    vocab_size=len(tokenizer),\n","    n_ctx=CONTEXT_LENGTH,\n","    bos_token_id=tokenizer.bos_token_id,\n","    eos_token_id=tokenizer.eos_token_id,\n",")\n","\n","model = GPT2LMHeadModel(config)\n","model_size = sum(t.numel() for t in model.parameters())\n","print(f\"GPT-2 size: {model_size/1000**2:.1f}M parameters\")\n","\n","tokenizer.pad_token = tokenizer.eos_token\n","data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)"],"metadata":{"id":"lWR0bAT8Ctew"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Train the model"],"metadata":{"id":"0oX6mTnTD6gL"}},{"cell_type":"code","source":["from huggingface_hub import notebook_login\n","notebook_login()"],"metadata":{"id":"svekPssrD8f3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import TrainingArguments, Trainer\n","import wandb\n","\n","HF_USER = \"shayharding\"\n","FT_MODEL = \"gpt2-reuters-textgen\"\n","\n","training_args = TrainingArguments(\n","    output_dir=\"./\" + FT_MODEL,\n","    hub_model_id=HF_USER + \"/\" + FT_MODEL,\n","    learning_rate=5e-4,\n","    num_train_epochs=2,\n","    gradient_accumulation_steps=8,\n","    weight_decay=0.01,\n","    auto_find_batch_size=True,\n","    fp16=True,\n","    eval_strategy=\"epoch\",\n","    lr_scheduler_type=\"cosine\",\n","    push_to_hub=True,\n","    logging_steps=10\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    processing_class=tokenizer,\n","    args=training_args,\n","    data_collator=data_collator,\n","    train_dataset=tokenized_dataset[\"train\"],\n","    eval_dataset=tokenized_dataset[\"validation\"]\n",")\n","\n","wandb.init(project=FT_MODEL)"],"metadata":{"id":"TG4ukwOFEn5b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer.train()"],"metadata":{"id":"UJuyMmTyFxN3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Use the model"],"metadata":{"id":"g-Ufww9HHlRX"}},{"cell_type":"code","source":["from transformers import pipeline\n","\n","pipe = pipeline(\"text-generation\", model=HF_USER + \"/\" + FT_MODEL)"],"metadata":{"id":"MLGpBKPBHmkX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sample = dataset['test'][2]\n","sample"],"metadata":{"id":"Dnm8L8_3H3yr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompt = f\"TITLE:{sample['title']}\\n\\nBODY:\"\n","pipe(prompt, max_new_tokens=128, pad_token_id=tokenizer.eos_token_id)"],"metadata":{"id":"ljasGcQhH7H7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompt = f\"TITLE:{sample['title']}\"\n","pipe(prompt, max_new_tokens=128, pad_token_id=tokenizer.eos_token_id)"],"metadata":{"id":"lqJXTxkfJfCn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Keep training the model"],"metadata":{"id":"aolMb9rOKQ1n"}},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForCausalLM\n","from transformers import TrainingArguments, Trainer\n","import wandb\n","\n","HF_USER = \"shayharding\"\n","FT_MODEL = \"gpt2-reuters-textgen\"\n","\n","model = AutoModelForCausalLM.from_pretrained(HF_USER + \"/\" + FT_MODEL)\n","tokenizer = AutoTokenizer.from_pretrained(HF_USER + \"/\" + FT_MODEL)\n","\n","training_args = TrainingArguments(\n","    output_dir=\"./\" + FT_MODEL,\n","    hub_model_id=HF_USER + \"/\" + FT_MODEL,\n","    learning_rate=5e-4,\n","    num_train_epochs=2,\n","    gradient_accumulation_steps=8,\n","    weight_decay=0.01,\n","    auto_find_batch_size=True,\n","    fp16=True,\n","    eval_strategy=\"epoch\",\n","    lr_scheduler_type=\"cosine\",\n","    push_to_hub=True,\n","    logging_steps=10\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    processing_class=tokenizer,\n","    args=training_args,\n","    data_collator=data_collator,\n","    train_dataset=tokenized_dataset[\"train\"],\n","    eval_dataset=tokenized_dataset[\"validation\"]\n",")\n","\n","wandb.init(project=FT_MODEL)"],"metadata":{"collapsed":true,"id":"M1ca1vlGKS6_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer.train()"],"metadata":{"id":"NVBqUOkRKscA"},"execution_count":null,"outputs":[]}]}