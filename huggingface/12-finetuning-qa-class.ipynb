{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyN5doVa3aY9IfD9B9559ehr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## Fine Tuning for QA Classification"],"metadata":{"id":"E6Gh87abLf_T"}},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"Nec5JYRxKWrp"},"outputs":[],"source":["! pip install transformers datasets seaborn bertviz umap-learn wandb"]},{"cell_type":"markdown","source":["### Load Dataset\n","Dataset was downloaded as a CSV from https://www.kaggle.com/datasets/ashpalsingh1525/imdb-movies-dataset"],"metadata":{"id":"k3xEldpauQOw"}},{"cell_type":"code","source":["import pandas as pd\n","\n","df = pd.read_csv('imdb_movies.csv')"],"metadata":{"id":"tOXVS2xruVvw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"Shape: {df.shape}\")\n","print(f\"Columns: {df.columns}\\n\")\n","df.head()"],"metadata":{"collapsed":true,"id":"pFOhWSJwuj_w"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Build Context and QAs"],"metadata":{"id":"3abIhw3yvUTQ"}},{"cell_type":"code","source":["def build_context_string(row):\n","    context = f\"{row['names']} is a {row['genre']} movie released in {row['date_x']} with budget of {row['budget_x']} had revenue {row['revenue']}.\"\n","\n","    if(description := row['overview']):\n","        context += f\"The movie is all about {description}\"\n","\n","    return context"],"metadata":{"id":"6bign1H4vCxo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def build_question_string(row, context):\n","    title = str(row['names'])\n","    genre = str(row['genre'])\n","    budget = str(row['budget_x'])\n","    revenue = str(row['revenue'])\n","    year = str(row['date_x'])\n","    description = str(row['overview'])\n","\n","    question_list = [['genre', genre], ['budget', budget], ['revenue', revenue], ['year', year], ['description', description]]\n","    qa_list = []\n","\n","    for question, answer in question_list:\n","        question_1 = f\"What is the {question} of the movie {title}?\"\n","        answer_1 = answer\n","        answer_start_1 = context.find(answer_1)\n","\n","        if answer_start_1 != -1:\n","            qa_list.append({\n","                'question': question_1,\n","                'id': f\"{title}_{question}\",\n","                'answers': [\n","                    {\n","                        'text': answer_1,\n","                        'answer_start': answer_start_1\n","                    },\n","                ],\n","                'is_impossible': False\n","            })\n","\n","    return qa_list"],"metadata":{"id":"vkuEG1sCwPiB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Build SQuaD JSON"],"metadata":{"id":"lY9PTaiO2JsM"}},{"cell_type":"code","source":["def build_squad_dataset(df):\n","  data_list = []\n","\n","  for idx, row in df.iterrows():\n","      context = build_context_string(row)\n","      qa_list = build_question_string(row, context)\n","\n","      if(len(qa_list) == 0):\n","          continue\n","\n","      data_list.append({\n","          'title': row['names'],\n","          'paragraphs': [{\n","                'context': context,\n","                'qas': qa_list\n","            }]\n","      })\n","\n","  return {\n","    'title': 'IMDB Movies QA V1',\n","    'data': data_list\n","  }"],"metadata":{"id":"D4g5io2W2Aa1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["squad_data = build_squad_dataset(df)\n","squad_data['data'][:2]"],"metadata":{"collapsed":true,"id":"SNlESCoF3uPE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Convert to Hugging Face dataset"],"metadata":{"id":"XtCZHuZL46a4"}},{"cell_type":"code","source":["from datasets import load_dataset, Dataset, DatasetDict\n","\n","def squad_dict_to_dataset(squad_dict):\n","    records = []\n","\n","    for entry in squad_dict[\"data\"]:\n","        title = entry['title']\n","\n","        for paragraph in entry['paragraphs']:\n","            context = paragraph['context']\n","            qas = paragraph['qas']\n","\n","            for qa in qas:\n","                question = qa['question']\n","                id = qa['id']\n","                is_impossible = qa['is_impossible']\n","                answers = qa['answers']\n","                answer_starts = [answer['answer_start'] for answer in answers]\n","                answer_texts = [answer['text'] for answer in answers]\n","\n","                records.append({\n","                    'title': title,\n","                    'context': context,\n","                    'question': question,\n","                    'id': id,\n","                    'is_impossible': is_impossible,\n","                    'answers': answers,\n","                    'answer_starts': answer_starts,\n","                    'answer_texts': answer_texts\n","                })\n","\n","    return Dataset.from_pandas(pd.DataFrame(records))"],"metadata":{"id":"Se9hy5-R489U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset = squad_dict_to_dataset(squad_data)\n","dataset"],"metadata":{"collapsed":true,"id":"zN830nyn6_fR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 70% train, 30% test\n","train_test = dataset.train_test_split(test_size=0.3)\n","\n","train_dataset = train_test['train']\n","test_dataset = train_test['test']\n","\n","# 20% test, 10% validation\n","validation_dataset = test_dataset.train_test_split(test_size=1/3)\n","\n","test_dataset = validation_dataset['train']\n","validation_dataset = validation_dataset['test']\n","\n","train_dataset, test_dataset, validation_dataset"],"metadata":{"collapsed":true,"id":"n56B3QiP7ocU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Prepare dataset"],"metadata":{"id":"B5fMIlsY85rT"}},{"cell_type":"code","source":["from transformers import DistilBertTokenizerFast, DistilBertForQuestionAnswering, TrainingArguments, Trainer, default_data_collator\n","import torch\n","\n","MODEL = 'distilbert-base-uncased'\n","\n","tokenizer = DistilBertTokenizerFast.from_pretrained(MODEL)"],"metadata":{"collapsed":true,"id":"3_Tj3Mhc86RM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["max_length = 384  # Max length of the encoding\n","doc_stride = 128  # Stride to handle long contexts\n","\n","def prepare_train_features(examples):\n","    # 1) Tokenize questions + contexts\n","    tokenized = tokenizer(\n","        examples[\"question\"],\n","        examples[\"context\"],\n","        max_length=max_length,\n","        truncation=\"only_second\",    # We only truncate the context if it's too long\n","        stride=doc_stride,\n","        return_overflowing_tokens=True,\n","        return_offsets_mapping=True,\n","        padding=\"max_length\",\n","    )\n","\n","    # 2) \"overflow_to_sample_mapping\" indicates which original sample each chunk belongs to\n","    sample_mapping = tokenized.pop(\"overflow_to_sample_mapping\")\n","    # 3) \"offset_mapping\" provides (char_start, char_end) for each token in the original text\n","    offset_mapping = tokenized.pop(\"offset_mapping\")\n","\n","    # 4) We'll need the answer information to map them back to token indices\n","    answers = examples[\"answers\"]\n","\n","    start_positions = []\n","    end_positions = []\n","\n","    # 5) Loop over each tokenized chunk\n","    for i, offsets in enumerate(offset_mapping):\n","        # The current chunk corresponds to the original example index:\n","        sample_idx = sample_mapping[i]\n","\n","        # Each example can have 1 or more answers; here it's typically 1\n","        answer = answers[sample_idx]\n","\n","        start_char = answer[0][\"answer_start\"]\n","        end_char = start_char + len(answer[0][\"text\"])\n","\n","        sequence_ids = tokenized.sequence_ids(i)\n","\n","        ctx_start = 0\n","        while sequence_ids[ctx_start] != 1:\n","            ctx_start += 1\n","        ctx_end = len(tokenized[\"input_ids\"][i]) - 1\n","        while sequence_ids[ctx_end] != 1:\n","            ctx_end -= 1\n","\n","        # If the answer text is not in this chunk (overflow window),\n","        # set start_positions/end_positions to something neutral (e.g. the start of the context)\n","        if not (start_char < offsets[ctx_end][1] and end_char > offsets[ctx_start][0]):\n","            start_positions.append(ctx_start)\n","            end_positions.append(ctx_start)\n","            continue\n","\n","        # Otherwise, find the first token that starts after or at the answer’s start_char\n","        start_idx = ctx_start\n","        while start_idx <= ctx_end and offsets[start_idx][0] <= start_char:\n","            start_idx += 1\n","        start_positions.append(start_idx - 1)\n","\n","        # Similarly, find the last token that ends before or at the answer’s end_char\n","        end_idx = ctx_end\n","        while end_idx >= ctx_start and offsets[end_idx][1] >= end_char:\n","            end_idx -= 1\n","        end_positions.append(end_idx + 1)\n","\n","    # 6) Store these positions in the returned dictionary\n","    tokenized[\"start_positions\"] = start_positions\n","    tokenized[\"end_positions\"] = end_positions\n","    return tokenized"],"metadata":{"id":"k6PrZdRs9dVD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset = DatasetDict({\n","    'train': train_dataset,\n","    'test': test_dataset,\n","    'validation': validation_dataset\n","})\n","\n","dataset"],"metadata":{"collapsed":true,"id":"rHgJEBgnEYLF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset['train'].column_names"],"metadata":{"id":"qkG9UiE0Lq9J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset = train_dataset.map(prepare_train_features, batched=True, remove_columns=dataset[\"train\"].column_names)\n","validation_dataset = validation_dataset.map(prepare_train_features, batched=True, remove_columns=dataset[\"validation\"].column_names)\n","\n","train_dataset, validation_dataset"],"metadata":{"collapsed":true,"id":"JnRWhmEwE2O8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Model Training"],"metadata":{"id":"5KTaPSBVM8S5"}},{"cell_type":"code","source":["def show_model_info(model, show_layers=False):\n","    \"\"\"Comprehensive model inspection\"\"\"\n","    config = model.config\n","    architecture = None\n","    model_heads = []\n","    model_type = \"Unknown\"\n","    id2label = None\n","    label2id = None\n","    merged_labels = None\n","    quant_type = \"None\"\n","    q = 0\n","\n","    gbs = model.get_memory_footprint() / 1e9\n","    param_count = model.num_parameters()\n","\n","    # Model architecture\n","    if hasattr(config, 'architectures') and config.architectures:\n","        architecture = config.architectures[0]\n","\n","    # Model heads\n","    try:\n","        if hasattr(model, 'base_model'):\n","            for module in model.modules():\n","                model_heads.append(type(module).__name__)\n","\n","                if module == model.base_model:\n","                    break\n","        else:\n","            for name, module in model.named_children()[:5]:\n","                model_heads.append(f\"{name}(type(module).__name__))\")\n","\n","        # Clean model head list\n","        model_heads = list(dict.fromkeys(model_heads))[:10]\n","    except Exception as e:\n","        model_heads = [f\"Detection failed: {str(e)[:50]}\"]\n","\n","    # Detect quantization\n","    if hasattr(config, \"quantization_config\") and config.quantization_config is not None:\n","        q_config = config.quantization_config\n","\n","        if hasattr(q_config, \"load_in_4bit\") and q_config.load_in_4bit == True:\n","            q = 4\n","            quant_type = f\"4-bit ({getattr(q_config, 'bnb_4bit_quant_type', 'unknown')})\"\n","        elif hasattr(q_config, \"load_in_8bit\") and q_config.load_in_8bit == True:\n","            q = 8\n","            quant_type = \"8-bit\"\n","    else:\n","        if hasattr(config, \"torch_dtype\") and config.torch_dtype is not None:\n","            q = config.torch_dtype.itemsize * 8\n","            quant_type = f\"FP{q} ({config.torch_dtype})\"\n","\n","    # Model type detection\n","    if hasattr(model.config, 'model_type'):\n","        model_type = model.config.model_type\n","\n","    # Label detection\n","    if  hasattr(model.config, 'label2id') and model.config.label2id is not None and hasattr(config, 'id2label') and config.id2label is not None:\n","\n","        id2label = model.config.id2label\n","        label2id = model.config.label2id\n","\n","        try:\n","            # Check for label consistency\n","            label2id_swap = {str(v): k for k, v in label2id.items()}\n","            id2label_str = {str(k): v for k, v in id2label.items()}\n","\n","            if id2label_str != label2id_swap:\n","                merged_labels = {}\n","                for k, v in id2label.items():\n","                    key = int(k) if isinstance(k, str) else k\n","                    merged_labels[key] = [v]\n","\n","                for k, v in label2id.items():\n","                    try:\n","                        v_int = int(v)\n","\n","                        if v_int in merged_labels:\n","                            merged_labels[v_int].append(k)\n","                            merged_labels[v_int] = list(set(merged_labels[v_int]))\n","                        else:\n","                            merged_labels[v_int] = [k]\n","                    except ValueError:\n","                        continue\n","\n","        except Exception as e:\n","            print(f\"Label validation error: {e}\")\n","\n","    # Basic model info\n","    print(f\"{'='*55}\")\n","    print(f\"MODEL: {getattr(config, '_name_or_path', 'Unknown')}\")\n","    print(f\"{'='*55}\")\n","\n","    print(f\"Model Type: {model_type}\")\n","\n","    if architecture is not None:\n","        print(f\"Architecture: {architecture}\")\n","\n","    if len(model_heads) > 0:\n","        print(f\"Model Structure: {' → '.join(model_heads)}\")\n","\n","    if hasattr(config, \"problem_type\") and config.problem_type is not None:\n","        print(f\"Problem Type: {config.problem_type}\")\n","\n","    if hasattr(config, \"vocab_size\"):\n","        print(f\"Vocab Size: {config.vocab_size:,}\")\n","\n","    if id2label is not None:\n","        print(\"\\nLabel Info:\")\n","\n","        if merged_labels is None:\n","            print(\"  ✅ id2label and label2id match\")\n","            print(f\"  Label count: {len(id2label)}\")\n","\n","            if len(id2label) <= 10:\n","                print(f\"  Labels: {id2label}\")\n","            else:\n","                sample_labels = dict(list(id2label.items())[:5])\n","                print(f\"  Labels (sample): {sample_labels}... (+{len(id2label)-5} more)\")\n","        else:\n","            print(\"  ⚠️ WARNING: Model id2label and label2id don't match\")\n","            print(f\"  Merged labels: {merged_labels}\")\n","\n","    print(f\"\\nParameters: {param_count:,}\")\n","    print(f\"Quantization: {quant_type}\")\n","    print(f\"Memory (actual): {gbs:.2f} GB\")\n","    print(f\"Memory (FP32 equiv): {param_count*4/1e9:.2f} GB\")\n","\n","    if gbs > 0:\n","        print(f\"Memory savings: {((param_count*4/1e9 - gbs) / (param_count*4/1e9) * 100):.1f}%\")\n","\n","    # Device info\n","    device = next(model.parameters()).device\n","    print(f\"\\nDevice: {device}\")\n","\n","    # Check if all components on same device\n","    devices = set()\n","    for name, param in model.named_parameters():\n","        devices.add(str(param.device))\n","    for name, buffer in model.named_buffers():\n","        devices.add(str(buffer.device))\n","\n","    if len(devices) > 1:\n","        print(f\"⚠️  WARNING: Model spans multiple devices: {devices}\")\n","    else:\n","        print(f\"✅ All components on: {device}\")\n","\n","    # Add training state info\n","    if hasattr(model, 'training'):\n","        mode = \"Training\" if model.training else \"Evaluation\"\n","        print(f\"\\nMode: {mode}\")\n","\n","    # Memory per layer breakdown\n","    if show_layers:\n","        print(f\"\\n{'Layer Breakdown':^55}\")\n","        print(f\"{'Layer':<30} {'Parameters':<14} {'Device'}\")\n","        print(\"-\" * 55)\n","        for name, param in model.named_parameters():\n","            # Only show layers with >1M params\n","            if param.numel() > 1000000:\n","                print(f\"{name[:28]:<30} {param.numel():>10,} {str(param.device):>10}\")"],"metadata":{"id":"_Gxgcv64N8TU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import wandb\n","model = DistilBertForQuestionAnswering.from_pretrained(MODEL)\n","training_dir = 'distilbert-imdq-qa'\n","batch_size = 8\n","\n","show_model_info(model)\n","\n","training_args = TrainingArguments(\n","    output_dir=training_dir,\n","    overwrite_output_dir=True,\n","    eval_strategy='epoch',\n","    learning_rate=3e-5,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    num_train_epochs=2,\n","    weight_decay=0.01,\n","    save_total_limit=1,\n","    save_steps=500,\n","    logging_steps=10\n",")"],"metadata":{"collapsed":true,"id":"A5qlNXTsMcDL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer = Trainer(\n","    model=model,\n","    processing_class=tokenizer,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=validation_dataset,\n","    data_collator=default_data_collator\n",")\n","\n","wandb.init(project=training_dir)"],"metadata":{"collapsed":true,"id":"OFwcb23iOZhS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer.train()"],"metadata":{"id":"6cuXRNIRPb84"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Log into Hugging Face\n","from google.colab import userdata\n","from huggingface_hub import login\n","login(token=userdata.get('HF_TOKEN'))"],"metadata":{"id":"IpNwSr9APggU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer.push_to_hub()"],"metadata":{"id":"IhQSqYNJPjj0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import pipeline\n","\n","HF_USER = \"shayharding\"\n","qa = pipeline(\"question-answering\", model=HF_USER + \"/\" + training_dir)"],"metadata":{"id":"-01M60JjPkAQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_row = df.iloc[0]\n","context = build_context_string(data_row)\n","question = f\"What is the genre of {data_row['names']}?\"\n","\n","print(f\"Context: {context}\\n\")\n","print(f\"Question: {question}\\n\")\n","print(f\"Answer: {qa(question=question, context=context)}\")"],"metadata":{"id":"UWvSScgZPmXQ"},"execution_count":null,"outputs":[]}]}