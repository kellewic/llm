{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"L4","authorship_tag":"ABX9TyNLieIJRtsFU4sYj8XDAFKd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## Quantizing"],"metadata":{"id":"YWpii6lDYIj6"}},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"VPKqH7SiYIAR"},"outputs":[],"source":["!pip install transformers torch bitsandbytes accelerate"]},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n","import torch\n","\n","MODEL=\"tiiuae/falcon-7b\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(MODEL)"],"metadata":{"id":"wSqMOh4QZN6X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def show_model_size(model):\n","    config = model.config\n","    q=0\n","\n","    if hasattr(config, \"quantization_config\") and config.quantization_config is not None:\n","        q_config = config.quantization_config\n","\n","        if hasattr(q_config, \"load_in_4bit\") and q_config.load_in_4bit == True:\n","            q = 4\n","        elif hasattr(q_config, \"load_in_8bit\") and q_config.load_in_8bit == True:\n","            q = 8\n","    else:\n","        if hasattr(config, \"torch_dtype\") and config.torch_dtype is not None:\n","            q = config.torch_dtype.itemsize * 8\n","\n","    gbs = model.get_memory_footprint() / 1e9\n","    print(f\"----- {q}-bit Model -----\")\n","    print(f\"Number of parameters: {model.num_parameters():,}\")\n","    print(f\"Memory footprint if FP32: {model.num_parameters()*4/1e9:.2f} GB\")\n","    print(f\"Memory footprint: {gbs:.2f} GB\")\n","\n","def generate(prompt):\n","    tokenized_text = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n","    output = model.generate(**tokenized_text, eos_token_id=tokenizer.eos_token_id, pad_token_id=tokenizer.eos_token_id ,do_sample=True, max_new_tokens=100)\n","    return tokenizer.decode(output[0], skip_special_tokens=True)\n","\n","## This prompt was on the Falcon-7B model card\n","prompt = \"Girafatron is obsessed with giraffes, the most glorious animal on the face of this Earth. Giraftron believes all other animals are irrelevant when compared to the glorious majesty of the giraffe.\\nDaniel: Hello, Girafatron!\\nGirafatron:\"\n","prompt"],"metadata":{"id":"zrmNrmQ2ea2-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Use 16-bit"],"metadata":{"id":"pQMO2kkvaN36"}},{"cell_type":"code","source":["model = AutoModelForCausalLM.from_pretrained(MODEL, torch_dtype=torch.bfloat16, device_map=\"auto\")"],"metadata":{"id":"kG2uLK6qZ9hj","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["show_model_size(model)"],"metadata":{"id":"nNOoZIYVwgV6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result = generate(prompt)\n","print(result)"],"metadata":{"id":"y8oD1iJngw7L"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Use 8-bit"],"metadata":{"id":"3mR-WC6iaVKi"}},{"cell_type":"code","source":["del model\n","\n","config = BitsAndBytesConfig(\n","    load_in_8bit=True\n",")\n","\n","model = AutoModelForCausalLM.from_pretrained(MODEL, quantization_config=config, device_map=\"auto\")"],"metadata":{"id":"rcPUaiqgaWq6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["show_model_size(model)"],"metadata":{"id":"f-4Av4A-0VM4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result = generate(prompt)\n","print(result)"],"metadata":{"id":"pFngnd4tcahm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Use 4-**bit**"],"metadata":{"id":"rmyEZLKzd4Du"}},{"cell_type":"code","source":["del model\n","\n","config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_use_double_quant=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.float16\n",")\n","\n","model = AutoModelForCausalLM.from_pretrained(MODEL, quantization_config=config, device_map=\"auto\")"],"metadata":{"id":"E7-04HJBd7R6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["show_model_size(model)"],"metadata":{"id":"zvACkPWm0au_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result = generate(prompt)\n","print(result)"],"metadata":{"id":"ErfN1E68knHa"},"execution_count":null,"outputs":[]}]}